{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from scipy.cluster.hierarchy import ward\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('./dataset/combined_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['x', 'y', 'z']]  # 입력 변수\n",
    "y = data['position']           # 출력 변수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['position'] = data['position'].astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('zero_combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperp_search(classifier, parameters, k, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Hyperparameter tuning via cross-validation\n",
    "    gs = GridSearchCV(classifier, parameters, cv=k, scoring = 'accuracy', refit=True, verbose=0, n_jobs=-1) # refit=True refits the model with the best found parameters on the whole dataset\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "\n",
    "    # Prediction on train and test sets with best model found\n",
    "    best_model = gs.best_estimator_\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "\n",
    "    # Results display\n",
    "    print(\"\\n \\033[1m ***Best result obtained*** \\033[0m \\n\")\n",
    "    print(\"accuracy (mean cross-validated score): %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "\n",
    "    print(\"\\n \\033[1m ***Scores obtained on train and test sets with best model*** \\033[0m \\n\")\n",
    "    print(\"f1          train %.3f   test %.3f\" % (f1_score(y_train, y_train_pred, average='macro'), f1_score(y_test, y_test_pred, average='macro'))) \n",
    "    print(\"recall      train %.3f   test %.3f\" % (recall_score(y_train, y_train_pred, average='macro'), recall_score(y_test, y_test_pred, average='macro'))) \n",
    "    print(\"precision   train %.3f   test %.3f\" % (precision_score(y_train, y_train_pred, average='macro'), precision_score(y_test, y_test_pred, average='macro'))) \n",
    "    print(\"accuracy    train %.3f   test %.3f\" % (accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred))) \n",
    "\n",
    "    print(\"\\n \\033[1m ***Classification report on test set*** \\033[0m \\n\")\n",
    "    print(classification_report(y_test, y_test_pred, target_names=['1', '2', '3', '4']))\n",
    "\n",
    "    print(\"\\n \\033[1m ***Confusion matrix on test set*** \\033[0m \\n\")\n",
    "    ConfusionMatrixDisplay(best_model, X_test, y_test, display_labels=['1', '2', '3', '4'], values_format='', cmap='Reds')\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode characters in position 18-20: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m classifier \u001b[38;5;241m=\u001b[39m KNeighborsClassifier()\n\u001b[0;32m      2\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m:np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m1\u001b[39m)}\n\u001b[1;32m----> 4\u001b[0m best_model_knn_avg \u001b[38;5;241m=\u001b[39m \u001b[43mhyperp_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m, in \u001b[0;36mhyperp_search\u001b[1;34m(classifier, parameters, k, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhyperp_search\u001b[39m(classifier, parameters, k, X_train, y_train, X_test, y_test):\n\u001b[0;32m      2\u001b[0m     \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Hyperparameter tuning via cross-validation\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     gs \u001b[38;5;241m=\u001b[39m GridSearchCV(classifier, parameters, cv\u001b[38;5;241m=\u001b[39mk, scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# refit=True refits the model with the best found parameters on the whole dataset\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     gs \u001b[38;5;241m=\u001b[39m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Prediction on train and test sets with best model found\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     best_model \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mClassNamePrefixFeaturesOutMixin\u001b[39;00m:\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;124;03m\"\"\"Mixin class for transformers that generate their own names by prefixing.\u001b[39;00m\n\u001b[0;32m   1149\u001b[0m \n\u001b[0;32m   1150\u001b[0m \u001b[38;5;124;03m    This mixin is useful when the transformer needs to generate its own feature\u001b[39;00m\n\u001b[1;32m-> 1151\u001b[0m \u001b[38;5;124;03m    names out, such as :class:`~sklearn.decomposition.PCA`. For example, if\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;124;03m    :class:`~sklearn.decomposition.PCA` outputs 3 features, then the generated feature\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;124;03m    names out are: `[\"pca0\", \"pca1\", \"pca2\"]`.\u001b[39;00m\n\u001b[0;32m   1154\u001b[0m \n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m    This mixin assumes that a `_n_features_out` attribute is defined when the\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;124;03m    transformer is fitted. `_n_features_out` is the number of output features\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;124;03m    that the transformer will return in `transform` of `fit_transform`.\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \n\u001b[0;32m   1159\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;124;03m    >>> import numpy as np\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;124;03m    >>> from sklearn.base import ClassNamePrefixFeaturesOutMixin\u001b[39;00m\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;124;03m    >>> class MyEstimator(ClassNamePrefixFeaturesOutMixin):\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;124;03m    ...     def fit(self, X, y=None):\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;124;03m    ...         self._n_features_out = X.shape[1]\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;124;03m    ...         return self\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;124;03m    >>> X = np.array([[1, 2], [3, 4]])\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;124;03m    >>> MyEstimator().fit(X).get_feature_names_out()\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;124;03m    array(['myestimator0', 'myestimator1'], dtype=object)\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_feature_names_out\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1173\u001b[0m         \u001b[38;5;124;03m\"\"\"Get output feature names for transformation.\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \n\u001b[0;32m   1175\u001b[0m \u001b[38;5;124;03m        The feature names out will prefixed by the lowercased class name. For\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;124;03m            Transformed feature names.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:827\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    826\u001b[0m     params \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 827\u001b[0m     groups \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroups\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    828\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m Bunch(\n\u001b[0;32m    829\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mBunch(fit\u001b[38;5;241m=\u001b[39mparams),\n\u001b[0;32m    830\u001b[0m         splitter\u001b[38;5;241m=\u001b[39mBunch(split\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroups\u001b[39m\u001b[38;5;124m\"\u001b[39m: groups}),\n\u001b[0;32m    831\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mBunch(score\u001b[38;5;241m=\u001b[39m{}),\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m routed_params\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\joblib\\parallel.py:1312\u001b[0m, in \u001b[0;36mParallel.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_managed_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1312\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\joblib\\parallel.py:1324\u001b[0m, in \u001b[0;36mParallel._initialize_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;124;03m\"\"\"Build a process or thread pool and return the number of workers\"\"\"\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1324\u001b[0m     n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39msupports_timeout:\n\u001b[0;32m   1327\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1328\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe backend class \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m does not support timeout. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1329\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have set \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in Parallel but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1330\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter will not be used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1331\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m   1332\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\joblib\\_parallel_backends.py:550\u001b[0m, in \u001b[0;36mLokyBackend.configure\u001b[1;34m(self, n_jobs, parallel, prefer, require, idle_worker_timeout, **memmappingexecutor_args)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FallbackToBackend(\n\u001b[0;32m    548\u001b[0m         SequentialBackend(nesting_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnesting_level))\n\u001b[1;32m--> 550\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers \u001b[38;5;241m=\u001b[39m \u001b[43mget_memmapping_executor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midle_worker_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_worker_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmemmappingexecutor_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel \u001b[38;5;241m=\u001b[39m parallel\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_jobs\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\joblib\\executor.py:20\u001b[0m, in \u001b[0;36mget_memmapping_executor\u001b[1;34m(n_jobs, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_memmapping_executor\u001b[39m(n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMemmappingExecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_memmapping_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\joblib\\executor.py:42\u001b[0m, in \u001b[0;36mMemmappingExecutor.get_memmapping_executor\u001b[1;34m(cls, n_jobs, timeout, initializer, initargs, env, temp_folder, context_id, **backend_args)\u001b[0m\n\u001b[0;32m     39\u001b[0m reuse \u001b[38;5;241m=\u001b[39m _executor_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m _executor_args \u001b[38;5;241m==\u001b[39m executor_args\n\u001b[0;32m     40\u001b[0m _executor_args \u001b[38;5;241m=\u001b[39m executor_args\n\u001b[1;32m---> 42\u001b[0m manager \u001b[38;5;241m=\u001b[39m \u001b[43mTemporaryResourcesManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# reducers access the temporary folder in which to store temporary\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# pickles through a call to manager.resolve_temp_folder_name. resolving\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# the folder name dynamically is useful to use different folders across\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# calls of a same reusable executor\u001b[39;00m\n\u001b[0;32m     48\u001b[0m job_reducers, result_reducers \u001b[38;5;241m=\u001b[39m get_memmapping_reducers(\n\u001b[0;32m     49\u001b[0m     unlink_on_gc_collect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     50\u001b[0m     temp_folder_resolver\u001b[38;5;241m=\u001b[39mmanager\u001b[38;5;241m.\u001b[39mresolve_temp_folder_name,\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbackend_args)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\joblib\\_memmapping_reducer.py:535\u001b[0m, in \u001b[0;36mTemporaryResourcesManager.__init__\u001b[1;34m(self, temp_folder_root, context_id)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;66;03m# It would be safer to not assign a default context id (less silent\u001b[39;00m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;66;03m# bugs), but doing this while maintaining backward compatibility\u001b[39;00m\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;66;03m# with the previous, context-unaware version get_memmaping_executor\u001b[39;00m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;66;03m# exposes too many low-level details.\u001b[39;00m\n\u001b[0;32m    534\u001b[0m     context_id \u001b[38;5;241m=\u001b[39m uuid4()\u001b[38;5;241m.\u001b[39mhex\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_current_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\joblib\\_memmapping_reducer.py:539\u001b[0m, in \u001b[0;36mTemporaryResourcesManager.set_current_context\u001b[1;34m(self, context_id)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_current_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, context_id):\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_context_id \u001b[38;5;241m=\u001b[39m context_id\n\u001b[1;32m--> 539\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_new_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\joblib\\_memmapping_reducer.py:564\u001b[0m, in \u001b[0;36mTemporaryResourcesManager.register_new_context\u001b[1;34m(self, context_id)\u001b[0m\n\u001b[0;32m    557\u001b[0m new_folder_name \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib_memmapping_folder_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    559\u001b[0m         os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id, context_id)\n\u001b[0;32m    560\u001b[0m )\n\u001b[0;32m    561\u001b[0m new_folder_path, _ \u001b[38;5;241m=\u001b[39m _get_temp_dir(\n\u001b[0;32m    562\u001b[0m     new_folder_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temp_folder_root\n\u001b[0;32m    563\u001b[0m )\n\u001b[1;32m--> 564\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_folder_finalizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_folder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_temp_folders[context_id] \u001b[38;5;241m=\u001b[39m new_folder_path\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\joblib\\_memmapping_reducer.py:580\u001b[0m, in \u001b[0;36mTemporaryResourcesManager.register_folder_finalizer\u001b[1;34m(self, pool_subfolder, context_id)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregister_folder_finalizer\u001b[39m(\u001b[38;5;28mself\u001b[39m, pool_subfolder, context_id):\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;66;03m# Register the garbage collector at program exit in case caller forgets\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;66;03m# to call terminate explicitly: note we do not pass any reference to\u001b[39;00m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;66;03m# ensure that this callback won't prevent garbage collection of\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;66;03m# parallel instance and related file handler resources such as POSIX\u001b[39;00m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;66;03m# semaphores and pipes\u001b[39;00m\n\u001b[0;32m    579\u001b[0m     pool_module_name \u001b[38;5;241m=\u001b[39m whichmodule(delete_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete_folder\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 580\u001b[0m     \u001b[43mresource_tracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool_subfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfolder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cleanup\u001b[39m():\n\u001b[0;32m    583\u001b[0m         \u001b[38;5;66;03m# In some cases the Python runtime seems to set delete_folder to\u001b[39;00m\n\u001b[0;32m    584\u001b[0m         \u001b[38;5;66;03m# None just before exiting when accessing the delete_folder\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[38;5;66;03m# because joblib should only use relative imports to allow\u001b[39;00m\n\u001b[0;32m    590\u001b[0m         \u001b[38;5;66;03m# easy vendoring.\u001b[39;00m\n\u001b[0;32m    591\u001b[0m         delete_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28m__import__\u001b[39m(\n\u001b[0;32m    592\u001b[0m             pool_module_name, fromlist\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete_folder\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    593\u001b[0m         )\u001b[38;5;241m.\u001b[39mdelete_folder\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:179\u001b[0m, in \u001b[0;36mResourceTracker.register\u001b[1;34m(self, name, rtype)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m\"\"\"Register a named resource, and increment its refcount.\"\"\"\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensure_running()\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mREGISTER\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:196\u001b[0m, in \u001b[0;36mResourceTracker._send\u001b[1;34m(self, cmd, name, rtype)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(name) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m512\u001b[39m:\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# posix guarantees that writes to a pipe of less than PIPE_BUF\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# bytes are atomic, and that PIPE_BUF >= 512\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname too long\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 196\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcmd\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrtype\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mascii\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m nbytes \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fd, msg)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m nbytes \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(msg)\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode characters in position 18-20: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':np.arange(3,50,1)}\n",
    "\n",
    "best_model_knn_avg = hyperp_search(classifier, parameters, 5, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
